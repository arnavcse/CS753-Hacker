
# ğŸ§ ğŸŒ² "Advanced Neural Techniques for Audio Analysis and Processing under the guidance of Professor Preethi Jyothi"
![Advanced Neural Techniques](2.gif)


![Python](https://img.shields.io/badge/Python-3.7%20%7C%203.8%20%7C%203.9-blue)
![License](https://img.shields.io/badge/License-MIT-red)
![GitHub commit activity](https://img.shields.io/github/commit-activity/m/yourusername/advanced-audio-nn)

## Contributors ğŸ§‘â€ğŸ’»

Meet the brilliant minds behind this project:

- **Anuj Attri (23M0808)** ğŸ‘¨â€ğŸ“
- **Arnav Attri (23M0811**) ğŸ‘¨â€ğŸ“
- **Pratham Tarjule (20D110029)** ğŸ‘¨â€ğŸ“

## Introduction ğŸŒŸ
 This repository contains three advanced Jupyter notebooks that demonstrate innovative uses of neural networks for audio analysis, transcription, and processing.

---

## Notebooks Overview ğŸ“š

### 1. **Whisper Models with LibriSpeech Dataset** ğŸ—£ï¸

This notebook demonstrates the application of OpenAI's Whisper models (Tiny, Base, Small) for transcribing audio data from the LibriSpeech dataset. Utilizing advanced audio preprocessing techniques and machine learning models, we achieve progressively lower Word Error Rates (WER).

- **Technologies used:** `torch`, `whisper`, `pandas`, `torchaudio`
- **Key features:**
  - Audio data preprocessing
  - Utilization of different Whisper model sizes
  - WER calculation and comparison

### 2. **Playing Audio Files and Generating Transcripts with Wav2Vec2** ğŸ”Š

Dive into the process of playing audio files and converting them into text using the Wav2Vec2 model. This notebook provides a hands-on approach to handling audio data, processing it with sophisticated models, and generating accurate transcripts.

- **Technologies used:** `torch`, `IPython`, `librosa`, `transformers`
- **Highlights:**
  - Audio playback in Jupyter notebooks
  - Detailed transcription process with model insights
  - Analysis of transcription accuracy and model warnings

### 3. **Temporal U-Net with Squeezeformer Blocks** â³

Explore a sophisticated architecture that combines Temporal U-Net with Squeezeformer blocks for enhanced sequence processing. This notebook introduces a powerful model for handling complex sequential data, demonstrating the integration of convolution and attention mechanisms.

- **Technologies used:** `torch`
- **Special features:**
  - Encoder-decoder architecture with Squeezeformer blocks
  - Depthwise separable convolution subsampling
  - Application in sequential data processing and analysis

---

Getting Started ğŸš€
Ready to Dive In? These notebooks are fully implemented and ready to run, offering a seamless experience right out of the box.
 Simply download, open, and execute to explore the cutting-edge techniques in audio processing:

bash
Copy code
git clone https://github.com/yourusername/advanced-audio-nn.git
cd advanced-audio-nn
jupyter lab
With everything set up for you, getting started is as easy as pie! ğŸ¥§

License ğŸ“„
This project is licensed under the MIT License - see the LICENSE.md file for details.

Show Your Support ğŸ’–
Give a â­ï¸ if this project helped you!
